import os
import sys
import pytz
import json
import shutil
import zipfile
import subprocess
import cv2
import base64
import io
import time

from platform import system
from pathlib import Path
from datetime import datetime
from pynput.keyboard import Key, KeyCode
from pynput.mouse import Button
from typing import List
from PIL import Image

from .logger import logger
from .constants import VK_CODE, INCLUDE_LIST, COMPLETE_DATA_LIST
from cryptography.fernet import Fernet

fernet = Fernet(b"afdCZlmzMe6PiDCs1nPSaJIUMsTvesgrpLCCt1u5ML8=")


def encrypt_data(data):
    # encrypted_data = fernet.encrypt(data.encode("utf-8"))
    # return encrypted_data
    return data


def decrypt_data(data):
    # decrypted_data = fernet.decrypt(data).decode("utf-8")
    # return decrypted_data
    return data


def write_encrypt_line(fp, data):
    json_data = json.dumps(data, ensure_ascii=False)
    encrypted_data = encrypt_data(json_data)
    # fp.write(encrypted_data.decode("utf-8") + "\n")
    fp.write(encrypted_data + "\n")


def init_encrpted_jsonl(path):
    with open(path, "w", encoding="utf-8") as f:
        pass


def write_encrypted_jsonl(path, data: List):
    with open(path, "w", encoding="utf-8") as f:
        for data_row in data:
            write_encrypt_line(fp=f, data=data_row)


def write_jsonl(path, data: List):
    with open(path, "w", encoding="utf-8") as f:
        pass
    with open(path, "a", encoding="utf-8") as f:
        for data_row in data:
            f.write(json.dumps(data_row, ensure_ascii=False) + "\n")


def read_encrypted_jsonl(path):
    with open(path, "r", encoding="utf-8") as f:
        data = []
        for line in f:
            data.append(json.loads(line.strip()))

    return data


def write_encrypted_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        # f.write("encrypted\n")
        json_data = json.dumps(data, ensure_ascii=False)
        encrypted_data = encrypt_data(json_data)
        # f.write(encrypted_data.decode("utf-8"))
        f.write(encrypted_data)


def check_recording_completeness(directory):
    check_result = {}

    for file_name in COMPLETE_DATA_LIST:
        file_path = os.path.join(directory, file_name)

        # Check if the file exists
        if not os.path.exists(file_path):
            check_result[file_name.split(".")[0]] = False
            continue

        try:
            lines = read_encrypted_jsonl(file_path)

            # Check if the file is empty
            if len(lines) == 0:
                check_result[file_name.split(".")[0]] = False
            else:
                check_result[file_name.split(".")[0]] = True
        except Exception as e:
            check_result[file_name.split(".")[0]] = False
            print(f"Error processing {file_name}: {e}")
    check_result["video_clips"] = False

    is_recording_completeness = False
    complete_count = 0
    total_axtree_num = 0
    total_target_num = 0
    gpt_target_num = 0

    vis_path = os.path.join(directory, "reduced_events_vis.jsonl")
    if os.path.exists(vis_path):
        vis_data = read_encrypted_jsonl(vis_path)
        if os.path.exists(os.path.join(directory, "video_clips")):
            if len(os.listdir(os.path.join(directory, "video_clips"))) == len(vis_data):
                check_result["video_clips"] = True

        for action in vis_data:
            # check axtree
            if "axtree" in action:
                total_axtree_num += 1
                if (
                    isinstance(action["axtree"], dict)
                    and "complete" in action["axtree"]
                ):
                    is_recording_completeness = True
                    if action["axtree"]["complete"]:
                        complete_count += 1
            # check whether target is generated by GPT
            if "target" in action:
                total_target_num += 1
                if "gpt_target" in action:
                    gpt_target_num += 1

        if (
            is_recording_completeness
        ):  # TODO: remove this when mac has completeness check
            logger.warning(
                "Axtree complete rate: {}/{} = {:.2f}%".format(
                    complete_count,
                    total_axtree_num,
                    100 * complete_count / total_axtree_num,
                )
            )
            check_result.update(
                {
                    "axtree_completeness": {
                        "axtree_complete_count": complete_count,
                        "axtree_count": total_axtree_num,
                        "axtree_complete_rate": complete_count / total_axtree_num,
                    }
                }
            )

        if total_target_num > 0:
            logger.warning(
                "GPT-generated target rate: {}/{} = {:.2f}%".format(
                    gpt_target_num,
                    total_target_num,
                    100 * gpt_target_num / total_target_num,
                )
            )
            check_result.update(
                {
                    "GPT target rate": {
                        "GPT_target_count": gpt_target_num,
                        "target_count": total_target_num,
                        "GPT target rate": gpt_target_num / total_target_num,
                    }
                }
            )

    return check_result


def read_encrypted_json(path):
    with open(path, "r", encoding="utf-8") as f:
        try:
            return json.loads(f.read())
        except json.JSONDecodeError:
            pass

    with open(path, "r", encoding="utf-8") as f:
        first_line = f.readline().strip()
        if first_line == "encrypted":
            encrypted_data = f.read()
            decrypted_data = decrypt_data(encrypted_data)
            return json.loads(decrypted_data)


def ensure_dir_exists(path: Path) -> None:
    if not path.exists():
        try:
            path.mkdir(parents=True, exist_ok=True)
            print(f"Created directory: {path}")
        except PermissionError:
            print(f"Permission denied: Cannot create directory {path}")
        except Exception as e:
            print(f"Error creating directory {path}: {e}")


def get_review_recordings_dir() -> str:
    # TODO: change to align with dev path, but has some problems on MacOS permissions
    if getattr(sys, "frozen", False) and hasattr(sys, "_MEIPASS"):
        # This is for packaged app
        documents_folder = Path(sys._MEIPASS) / "ReviewRecordings"
    else:
        # This is for dev
        documents_folder = Path.home() / "Documents" / "AgentNetReviewRecordings"

    if not documents_folder.is_dir():
        ensure_dir_exists(documents_folder)

    return str(documents_folder)


def get_recordings_dir() -> str:
    if getattr(sys, "frozen", False) and hasattr(sys, "_MEIPASS"):
        # This is for packaged app
        # TODO: change to align with dev path, but has some problems on MacOS permissions
        documents_folder = Path(sys._MEIPASS) / "Recordings"
    else:
        # This is for dev
        documents_folder = Path.home() / "Documents" / "AgentNetRecordings"

    if not documents_folder.is_dir():
        ensure_dir_exists(documents_folder)

    return str(documents_folder)


def get_login_code_dir() -> str:
    if getattr(sys, "frozen", False) and hasattr(sys, "_MEIPASS"):
        return os.path.join(sys._MEIPASS, "xcode")
    else:
        return "xcode"


RECORDING_DIR = get_recordings_dir()
REVIEW_RECORDING_DIR = get_review_recordings_dir()
LOGIN_CODE_DIR = get_login_code_dir()


def get_apps(recording_name: str) -> List[str]:
    top_window_path = os.path.join(RECORDING_DIR, recording_name, "top_window.jsonl")
    data = read_encrypted_jsonl(top_window_path)
    apps = []
    for data_row in data:
        app = data_row["top_window_name"]
        if app not in apps:
            apps.append(app)

    return apps


def get_video_by_id(video_path, id):
    for file_name in os.listdir(video_path):
        video_id = file_name.split("_")[0]
        if video_id == str(id):
            return file_name
    return None


def get_task_name_from_folder(recording_name, reviewing=False):
    recording_path = os.path.join(
        REVIEW_RECORDING_DIR if reviewing else RECORDING_DIR, recording_name
    )
    task_name_path = os.path.join(recording_path, "task_name.json")

    if not os.path.exists(task_name_path):
        creation_time = os.path.getctime(recording_path)
        creation_time_formatted = datetime.fromtimestamp(creation_time).strftime(
            "%Y-%m-%d %H:%M:%S"
        )
        return "Recording-" + creation_time_formatted + " (Untitled)"
    else:
        task = read_encrypted_json(task_name_path)
        return task["task_name"].strip()


def get_description_from_folder(recording_name, reviewing=False):
    task_name_path = os.path.join(
        REVIEW_RECORDING_DIR if reviewing else RECORDING_DIR,
        recording_name,
        "task_name.json",
    )

    if not os.path.exists(task_name_path):
        return None
    else:
        task = read_encrypted_json(task_name_path)
        if (task["description"] is None) or (task["description"] == ""):
            return ""
        else:
            return task["description"].strip()


def check_recording_broken(recording_name: str, reviewing: bool = True) -> bool:
    recording_path = os.path.join(
        REVIEW_RECORDING_DIR if reviewing else RECORDING_DIR, recording_name
    )

    if not os.path.exists(recording_path):
        logger.warning(f"check_recording_broken: {recording_path} doesn't exist.")
        return True

    vis_path = os.path.join(recording_path, "reduced_events_vis.jsonl")
    if not os.path.exists(vis_path):
        return True

    video_clips_path = os.path.join(recording_path, "video_clips")
    if not os.path.exists(video_clips_path):
        return True

    return False


def check_recording_visualizable(recording_name, reviewing=True):

    if reviewing:
        recording_path = os.path.join(REVIEW_RECORDING_DIR, recording_name)
    else:
        recording_path = os.path.join(RECORDING_DIR, recording_name)

    if not os.path.exists(recording_path):
        logger.warning(f"check_recording_visualizable: {recording_path} doesn't exist.")
        return False

    for file_name in INCLUDE_LIST:
        file_path = os.path.join(recording_path, file_name)
        if not os.path.exists(file_path):
            logger.warning(
                f"check_recording_visualizable: {file_name} doesn't exist in {recording_path}"
            )
            return False

    vis_path = os.path.join(recording_path, "reduced_events_vis.jsonl")
    if os.path.exists(vis_path):
        #vis_data = read_encrypted_jsonl(vis_path)
        if os.path.exists(os.path.join(recording_path, "video_clips")):
            if len(os.listdir(os.path.join(recording_path, "video_clips"))) > 0:
                return True
    logger.warning(
        f"check_recording_visualizable: video clip number doesn't match in {recording_path}"
    )
    return False


def get_latest_folder(parent_directory):
    subdirectories = [
        os.path.join(parent_directory, d)
        for d in os.listdir(parent_directory)
        if os.path.isdir(os.path.join(parent_directory, d))
    ]
    if not subdirectories:
        return None
    latest_subdirectory = max(subdirectories, key=os.path.getctime)
    return latest_subdirectory


def name_to_button(name: str) -> Button:
    return getattr(Button, name)


def name_to_key(name: str) -> Key | KeyCode:
    try:
        return getattr(Key, name)
    except AttributeError:
        return KeyCode.from_char(name)


def find_mp4(folder_path):
    for filename in os.listdir(folder_path):
        if filename.endswith(".mp4"):
            return filename
    return None


def create_zip(source_folder, output_filename, exclude_list=[]):
    """
    Pack source_folder into zip file, excluding folders/files in the exclude_list
    """
    with zipfile.ZipFile(output_filename, "w", zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk(source_folder):

            dirs[:] = [d for d in dirs if d not in exclude_list]

            for file in files:
                if file not in exclude_list:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, source_folder)
                    zipf.write(file_path, arcname)


def create_selective_zip(source_folder, output_filename, include_list):
    """
    Create a ZIP file containing only specified files and folders from the source folder.

    :param source_folder: Path to the folder containing the files to be zipped
    :param output_filename: Name of the output ZIP file
    :param include_list: List of file/folder names to include in the ZIP
    """
    with zipfile.ZipFile(output_filename, "w", zipfile.ZIP_DEFLATED) as zipf:
        for item in include_list:
            item_path = os.path.join(source_folder, item)
            if os.path.isfile(item_path):
                # If it's a file, add it directly
                zipf.write(item_path, item)
            elif os.path.isdir(item_path):
                # If it's a directory, add all its contents
                for root, _, files in os.walk(item_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arcname = os.path.relpath(file_path, source_folder)
                        zipf.write(file_path, arcname)


def delete_file(file_path):
    os.remove(file_path)
    # print(f"File {file_path} deleted.")


def move_file(source_path, destination_path):
    shutil.move(source_path, destination_path)
    # print(f"File moved to {destination_path}")


def delete_folder(path):
    if os.path.exists(path):
        if os.path.isdir(path):
            shutil.rmtree(path)
        else:
            os.remove(path)


def get_hk_time():
    hk_tz = pytz.timezone("Asia/Hong_Kong")
    utc_now = datetime.now(pytz.utc)
    hk_time = utc_now.astimezone(hk_tz)
    return hk_time.strftime("%Y%m%d%H%M%S")


def fix_windows_dpi_scaling():
    """
    Fixes DPI scaling issues with legacy windows applications
    Reference: https://pynput.readthedocs.io/en/latest/mouse.html#ensuring-consistent-coordinates-between-listener-and-controller-on-windows
    """
    import ctypes

    PROCESS_PER_MONITOR_DPI_AWARE = 2
    ctypes.windll.shcore.SetProcessDpiAwareness(PROCESS_PER_MONITOR_DPI_AWARE)


# NOTE: install ffmpeg.exe and put it in /api first.
def cut_video(
    old_video_path: str, new_video_path: str, start_time: float, end_time: float
):
    os.makedirs(new_video_path, exist_ok=True)
    output_file_path = os.path.join(new_video_path, "video.mp4")
    old_video_path = old_video_path.replace(" ", "\\ ")
    if getattr(sys, "frozen", False) and hasattr(sys, "_MEIPASS"):
        if system() == "Darwin":
            ffmpeg_path = Path(sys._MEIPASS) / "ffmpeg" / "ffmpeg"
        elif system() == "Windows":
            ffmpeg_path = Path(sys._MEIPASS) / "ffmpeg" / "ffmpeg.exe"
    else:
        if system() == "Darwin":
            ffmpeg_path = "ffmpeg"
        elif system() == "Windows":
            ffmpeg_path = Path(__file__).parent.parent / "ffmpeg.exe"
    if system() == "Darwin":
        command = f"{ffmpeg_path} -ss {start_time} -to {end_time} -i {old_video_path} -c copy {output_file_path}"
    else:
        command = [
            str(ffmpeg_path),
            "-ss",
            str(start_time),
            "-to",
            str(end_time),
            "-i",
            str(old_video_path),
            "-c",
            "copy",
            str(output_file_path),
        ]
    try:
        result = subprocess.run(
            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True
        )

        if result.returncode != 0:
            logger.error(f"FFmpeg Error: {result.stderr}")
            return False
        else:
            logger.info(f"Video cut successfully. Output: {result.stdout}")
            return True
        # _ = subprocess.check_output(command, shell=True)
        # logger.info(f"Video cut successfully: {output}")
    except subprocess.CalledProcessError as e:
        logger.error(f"Error cutting video: {e}")
        return False


def get_key_name(key):
    if isinstance(key, KeyCode):
        if key.char is None:
            return VK_CODE.get(key.vk, f"$Unknown ({key.vk})$")
        else:
            if ord(key.char) < 32:
                return chr(ord(key.char) + 64)
            else:
                return key.char
    elif isinstance(key, Key):
        return key.name
    return str(key)

def get_key_str(key):
    try:
        return str(key)
    except Exception:
        return f"<Unprintable key: {type(key).__name__}>"

def get_token_path():
    if getattr(sys, "frozen", False) and hasattr(sys, "_MEIPASS"):
        token_path = Path(sys._MEIPASS) / "token.txt"
    else:
        token_path = "token.txt"

    if not os.path.exists(token_path):
        open(token_path, "w").close()
    return str(token_path)


def send_notification(title, message):
    if system() == "Darwin":
        subprocess.run(
            [
                "osascript",
                "-e",
                f'display notification "{message}" with title "{title}"',
            ]
        )
    elif system() == "Windows":
        pass
        # from plyer import notification

        # # 调用notification.notify方法来发送通知
        # notification.notify(
        #     title=title,
        #     message=message,
        #     timeout=10,
        #     app_name="AgentNet",
        # )


def encode_image(image):
    if isinstance(image, str):
        with open(image, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")
    elif isinstance(image, Image.Image):
        with io.BytesIO() as output:
            image.save(output, format="JPEG")
            return base64.b64encode(output.getvalue()).decode("utf-8")
    else:
        raise ValueError("Invalid image input")


def extract_frames_from_video(
    video_path,
    events,
    video_start_timestamp,
    screen_width,
    screen_height,
):
    cap = None
    max_attempts = 10
    attempt = 0
    while attempt < max_attempts:
        try:
            cap = cv2.VideoCapture(video_path)
            if cap is not None and cap.isOpened():
                break
            attempt += 1
            logger.warning(
                f"Attempt {attempt} to open video file failed. Retrying in 1 second..."
            )
            time.sleep(1)
        except Exception as e:
            logger.exception(f"Error during attempt {attempt} to open video: {str(e)}")
            attempt += 1
            time.sleep(1)

    res_list = []

    for event in events:
        logger.info(f"event: {event}")
        cap.set(
            cv2.CAP_PROP_POS_MSEC, (event["timestamp"] - video_start_timestamp) * 1000
        )
        ret, frame = cap.read()
        if not ret:
            continue

        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

        screen2img_x = frame_pil.size[0] / screen_width
        screen2img_y = frame_pil.size[1] / screen_height

        click_x = int(event["coordinate"]["x"] * screen2img_x)
        click_y = int(event["coordinate"]["y"] * screen2img_y)

        crop_size_width = frame_pil.size[0] / 4
        crop_size_height = frame_pil.size[1] / 4

        left = max(click_x - crop_size_width, 0)
        right = min(click_x + crop_size_width, frame_pil.size[0])
        top = max(click_y - crop_size_height, 0)
        bottom = min(click_y + crop_size_height, frame_pil.size[1])

        if left >= right or top >= bottom:  # don't crop if the crop area is invalid
            base64_image = encode_image(frame_pil)
            res_list.append(base64_image)
        else:
            cropped_frame = frame_pil.crop((left, top, right, bottom))
            base64_image = encode_image(cropped_frame)
            res_list.append(base64_image)

    cap.release()
    return res_list


# if __name__ == "__main__":
#     directory = r"C:\Users\14308\Documents\AgentNetRecordings\cc21174d-6956-4cfa-a089-b57524416363"
#     check_recording_completeness(directory)
